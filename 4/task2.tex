\subsection{原理と方法}
本節では，モンテカルロ法を用いて円周率 $\pi$ を推定する原理と，
実際に用いる計算手順をまとめる\cite{exp2025}．

まず，次の定積分が成り立つことを用いる\cite{exp2025}．
\begin{equation}
  \int_0^1 \frac{4}{1+x^2}\,\mathrm{d}x = \pi .
  \label{eq:int-pi}
\end{equation}
区間 $[0,1]$ 上の一様分布に従う確率変数 $X$ を考えると，
その確率密度関数は
\[
  p_X(x) =
  \begin{cases}
    1 & (0 \le x \le 1),\\
    0 & (\text{それ以外})
  \end{cases}
\]
である．このとき，任意の可積分関数 $g(x)$ に対して
\[
  \mathbb{E}[g(X)]
  = \int_0^1 g(x)\,p_X(x)\,\mathrm{d}x
  = \int_0^1 g(x)\,\mathrm{d}x
\]
が成り立つ．$g(x)=4/(1+x^2)$ とおけば，
式 \eqref{eq:int-pi} は
\begin{equation}
  \pi
  = \int_0^1 \frac{4}{1+x^2}\,\mathrm{d}x
  = \mathbb{E}\!\left[\frac{4}{1+X^2}\right]
  \label{eq:pi-as-expectation}
\end{equation}
と書き換えられる．したがって，
$\pi$ は確率変数 $Y = 4/(1+X^2)$ の期待値として表される．

式 \eqref{eq:pi-as-expectation} より，モンテカルロ法では
\[
  \hat{\pi}_M = \frac{1}{M}\sum_{k=1}^{M} \frac{4}{1+X_k^2}
\]
を計算することで $\pi$ の推定値 $\hat{\pi}_M$ を得る\cite{exp2025}。
 ここで $X_k$ は $U[0,1]$ に従う独立な乱数である。
本実験ではさらに，推定値の精度を評価するために，分割平均（blocking）に基づく分散推定を用いる。
 サンプル列を $N_d$ 個のブロックに分割し，各ブロックに対して
\[
  \bar{f}_i = \frac{1}{N_{d,i}}\sum_{x\in\text{block }i} \frac{4}{1+x^2}
\]
を計算する。これらのブロック平均の標本分散を用いると，推定値 $\hat{\pi}_M$ の分散は
\[
  \widehat{\mathrm{Var}}(\hat{\pi}_M)
  = \frac{1}{N_d(N_d-1)}
  \sum_{i=1}^{N_d} (\bar{f}_i - \hat{f})^2
\]
と推定される。これはブロック平均が互いに独立とみなせる場合に成り立つ標準的な不偏分散推定式であり，
 推定量 $\hat{\pi}_M$ の標準誤差を近似的に与える。


\subsection{実装上の工夫}
本実験ではサンプル数 $M$ を $10, 10^3, 10^5, 10^7$ と増加させながら，
式 (5.10) に基づくモンテカルロ積分を行う．
計算負荷が大きくなるため，以下の点に留意して実装した．

\begin{itemize}
  \item \textbf{完全ベクトル化による高速化}  
  Python の for ループは極端に遅いため，
  乱数生成から積分評価
  \[
    \frac{4}{1 + X^2}
  \]
  の計算までを NumPy の配列演算として一度に実行した．  
  これにより Python レベルのループを排除し，
  C 実装による高速な要素演算が可能になる．

  \item \textbf{形状 (10, M) の乱数生成}  
  10 回の独立試行を行うため，
  毎回乱数を生成するのではなく，
  あらかじめ形状 $(10, M)$ の乱数行列を生成した．  
  これにより，
  乱数生成コストを 1 回にまとめつつ，
  同じ処理を 10 行に対して並列に実行できる．

  \item \textbf{in-place 演算の利用}  
  NumPy の in-place 演算（例：\verb|s *= s|, \verb|np.reciprocal(out=s)|）
  を積極的に利用することで，
  中間配列の生成を避け，  
  メモリ消費とメモリアロケーション時間を削減した．  
  特に $M = 10^7$ のような大規模計算では，
  配列の再生成がボトルネックになるため有効である．

  \item \textbf{標本平均の同時計算}  
  10 行分の計算結果に対して，
  NumPy の \verb|mean(axis=1)| を用いて
  一度に標本平均を求めることで，
  試行ごとのループ処理を回避した．
\end{itemize}

上記の工夫により，大規模サンプルに対しても
純粋 Python 実装と比べて大幅に高速な実行が可能となった．


\subsection{結果}
サンプル数 $M = 10, 10^3, 10^5, 10^7$ について，
 各 $M$ につき 10 回の独立試行を行い，推定値 $\hat{\pi}_M$ と精度（標準誤差推定値）を求めた。
 結果の平均値を表 \ref{tab:pi-results} にまとめる。
\begin{table}[h]
  \centering
  \caption{$\pi$ の推定結果と精度（標準誤差推定値）}
  \label{tab:pi-results}
  \begin{tabular}{c|c|c}
    \hline
    サンプル数 $M$ & $\hat{\pi}_M$（平均） & 精度（標準誤差）\\
    \hline
    $10$ & $3.2023$ & $1.613\times 10^{-1}$\\
    $10^3$ & $3.1282$ & $2.046\times 10^{-2}$\\
    $10^5$ & $3.1410$ & $2.032\times 10^{-3}$\\
    $10^7$ & $3.14165$ & $2.033\times 10^{-4}$\\
    \hline
  \end{tabular}
\end{table}
サンプル数が増えるにつれて推定値は理論値 $\pi = 3.141592\ldots$ に収束し，標準誤差は $M^{-1/2}$ に比例して減少した。


\subsubsection{考察}

表 \ref{tab:pi-results} の結果より，推定値 $\hat{\pi}_M$ はサンプル数の増加とともに理論値に近づいており，
 モンテカルロ法が大数の法則に従って収束していることが確認できる。
また，精度（標準誤差）については，解析的に求めた $f(X)=4/(1+X^2)$ の分散
\[
  \mathrm{Var}(f(X)) = 2\pi + 4 - \pi^2 \approx 0.41358
\]
を用いると，推定量の理論的標準誤差は
\[
  \sqrt{\frac{\mathrm{Var}(f(X))}{M}} \approx \frac{0.64294}{M^{1/2}} = \frac{2.03367}{\sqrt{10M}}
\]
 で与えられる。これは $M^{-1/2}$ に比例して減少する。
 実験で得られた標準誤差もこの理論値と一致しており，特に $M\ge 10^3$ では誤差が $1\%$ 未満の精度で一致した。
 したがって，式（5.9）で与えられるブロック平均に基づく分散推定が妥当であることが確認できる。
さらに，$M=10^7$ の場合には $\hat{\pi}_M = 3.14165$ と理論値との差が $6\times 10^{-5}$ 程度となり，
 モンテカルロ法としては十分な精度が得られた。
 これは、サンプル数を増やせば精度が向上する一方，収束速度が $M^{-1/2}$ に制限されるという，
 モンテカルロ法の特性を示している。
